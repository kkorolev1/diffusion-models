{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import os\n",
    "\n",
    "from model.datasets import get_loaders\n",
    "from model.ddpm import DiffusionTrainer, DiffusionSampler\n",
    "from model.unet import Unet\n",
    "from model.training import train, sample\n",
    "from model.utils import SaveBestModel, load_model, plot_images\n",
    "from model.metrics import fid_score\n",
    "\n",
    "import gc\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7087"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "CUDA = 0\n",
    "batch_size = 64\n",
    "\n",
    "train_loader, val_loader = get_loaders('cifar10', batch_size=batch_size)\n",
    "device = torch.device(f\"cuda:{CUDA}\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'lr': 2e-4,\n",
    "    'start_epoch': 0,\n",
    "    'n_epochs': 5,\n",
    "    'warmup': 5000,\n",
    "    'model_path': 'bin/cifar10.pth'\n",
    "}\n",
    "\n",
    "unet = Unet(T=1000, ch=128, ch_mult=[1, 2, 2, 2], attn=[1], num_res_blocks=2, dropout=0.1)\n",
    "trainer = DiffusionTrainer(unet).to(device)\n",
    "\n",
    "optimizer = optim.Adam(trainer.parameters(), lr=config['lr'])\n",
    "#optimizer = optim.SGD(model.parameters(), lr=args.lr)\n",
    "#scheduler = torch.optim.lr_scheduler.LambdaLR(optim, lr_lambda=lambda epoch: min(epoch, config['warmup']) / config['warmup'])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "\n",
    "model_saver = SaveBestModel()\n",
    "\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1/5: 100%|██████████| 704/704 [05:26<00:00,  2.15it/s]\n",
      "Validating epoch 1/5: 100%|██████████| 79/79 [00:11<00:00,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.08122\n",
      "val loss: 0.04115\n",
      "New best model with loss 0.04115 is saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 2/5: 100%|██████████| 704/704 [05:22<00:00,  2.18it/s]\n",
      "Validating epoch 2/5: 100%|██████████| 79/79 [00:11<00:00,  6.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.03826\n",
      "val loss: 0.03500\n",
      "New best model with loss 0.03500 is saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 3/5:   4%|▎         | 26/704 [00:12<05:26,  2.07it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29761/2196985902.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/diffusion-models/model/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, scheduler, train_loader, val_loader, device, n_epochs, start_epoch, model_saver, model_path, writer)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'Training epoch {epoch+1}/{n_epochs}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'Validating epoch {epoch+1}/{n_epochs}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/diffusion-models/model/training.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, optimizer, dataloader, device, tqdm_desc)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             adam(params_with_grad,\n\u001b[0m\u001b[1;32m    235\u001b[0m                  \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                  \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    301\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;31m# update step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0mstep_t\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mweight_decay\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(\n",
    "    trainer,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    device,\n",
    "    config['start_epoch'] + config['n_epochs'],\n",
    "    config['start_epoch'],\n",
    "    model_saver,\n",
    "    config['model_path'],\n",
    "    writer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DiffusionSampler(\n",
       "  (model): Unet(\n",
       "    (time_embedding): TimeEmbedding(\n",
       "      (timembedding): Sequential(\n",
       "        (0): Embedding(1000, 128)\n",
       "        (1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (2): Swish()\n",
       "        (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (head): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (downblocks): ModuleList(\n",
       "      (0): ResBlock(\n",
       "        (block1): Sequential(\n",
       "          (0): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (1): Swish()\n",
       "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (temb_proj): Sequential(\n",
       "          (0): Swish()\n",
       "          (1): Linear(in_features=512, out_features=128, bias=True)\n",
       "        )\n",
       "        (block2): Sequential(\n",
       "          (0): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (1): Swish()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (shortcut): Identity()\n",
       "        (attn): Identity()\n",
       "      )\n",
       "      (1): ResBlock(\n",
       "        (block1): Sequential(\n",
       "          (0): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (1): Swish()\n",
       "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (temb_proj): Sequential(\n",
       "          (0): Swish()\n",
       "          (1): Linear(in_features=512, out_features=128, bias=True)\n",
       "        )\n",
       "        (block2): Sequential(\n",
       "          (0): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (1): Swish()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (shortcut): Identity()\n",
       "        (attn): Identity()\n",
       "      )\n",
       "      (2): DownSample(\n",
       "        (main): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "      (3): ResBlock(\n",
       "        (block1): Sequential(\n",
       "          (0): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (1): Swish()\n",
       "          (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (temb_proj): Sequential(\n",
       "          (0): Swish()\n",
       "          (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "        (block2): Sequential(\n",
       "          (0): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (1): Swish()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (shortcut): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (attn): AttnBlock(\n",
       "          (group_norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (proj_q): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (proj_k): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (proj_v): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): ResBlock(\n",
       "        (block1): Sequential(\n",
       "          (0): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (1): Swish()\n",
       "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (temb_proj): Sequential(\n",
       "          (0): Swish()\n",
       "          (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "        (block2): Sequential(\n",
       "          (0): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (1): Swish()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (shortcut): Identity()\n",
       "        (attn): AttnBlock(\n",
       "          (group_norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (proj_q): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (proj_k): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (proj_v): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): DownSample(\n",
       "        (main): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "      (6): ResBlock(\n",
       "        (block1): Sequential(\n",
       "          (0): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (1): Swish()\n",
       "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (temb_proj): Sequential(\n",
       "          (0): Swish()\n",
       "          (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "        (block2): Sequential(\n",
       "          (0): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (1): Swish()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (shortcut): Identity()\n",
       "        (attn): Identity()\n",
       "      )\n",
       "      (7): ResBlock(\n",
       "        (block1): Sequential(\n",
       "          (0): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (1): Swish()\n",
       "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (temb_proj): Sequential(\n",
       "          (0): Swish()\n",
       "          (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "        (block2): Sequential(\n",
       "          (0): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (1): Swish()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (shortcut): Identity()\n",
       "        (attn): Identity()\n",
       "      )\n",
       "      (8): DownSample(\n",
       "        (main): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "      (9): ResBlock(\n",
       "        (block1): Sequential(\n",
       "          (0): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (1): Swish()\n",
       "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (temb_proj): Sequential(\n",
       "          (0): Swish()\n",
       "          (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "        (block2): Sequential(\n",
       "          (0): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (1): Swish()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (shortcut): Identity()\n",
       "        (attn): Identity()\n",
       "      )\n",
       "      (10): ResBlock(\n",
       "        (block1): Sequential(\n",
       "          (0): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (1): Swish()\n",
       "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (temb_proj): Sequential(\n",
       "          (0): Swish()\n",
       "          (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "        (block2): Sequential(\n",
       "          (0): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (1): Swish()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (shortcut): Identity()\n",
       "        (attn): Identity()\n",
       "      )\n",
       "    )\n",
       "    (middleblocks): ModuleList(\n",
       "      (0): ResBlock(\n",
       "        (block1): Sequential(\n",
       "          (0): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (1): Swish()\n",
       "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (temb_proj): Sequential(\n",
       "          (0): Swish()\n",
       "          (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "        (block2): Sequential(\n",
       "          (0): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (1): Swish()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (shortcut): Identity()\n",
       "        (attn): AttnBlock(\n",
       "          (group_norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (proj_q): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (proj_k): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (proj_v): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (1): ResBlock(\n",
       "        (block1): Sequential(\n",
       "          (0): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (1): Swish()\n",
       "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (temb_proj): Sequential(\n",
       "          (0): Swish()\n",
       "          (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "        (block2): Sequential(\n",
       "          (0): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (1): Swish()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (shortcut): Identity()\n",
       "        (attn): Identity()\n",
       "      )\n",
       "    )\n",
       "    (upblocks): ModuleList(\n",
       "      (0): ResBlock(\n",
       "        (block1): Sequential(\n",
       "          (0): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "          (1): Swish()\n",
       "          (2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (temb_proj): Sequential(\n",
       "          (0): Swish()\n",
       "          (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "        (block2): Sequential(\n",
       "          (0): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (1): Swish()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (attn): Identity()\n",
       "      )\n",
       "      (1): ResBlock(\n",
       "        (block1): Sequential(\n",
       "          (0): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "          (1): Swish()\n",
       "          (2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (temb_proj): Sequential(\n",
       "          (0): Swish()\n",
       "          (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "        (block2): Sequential(\n",
       "          (0): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (1): Swish()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (attn): Identity()\n",
       "      )\n",
       "      (2): ResBlock(\n",
       "        (block1): Sequential(\n",
       "          (0): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "          (1): Swish()\n",
       "          (2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (temb_proj): Sequential(\n",
       "          (0): Swish()\n",
       "          (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "        (block2): Sequential(\n",
       "          (0): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (1): Swish()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (attn): Identity()\n",
       "      )\n",
       "      (3): UpSample(\n",
       "        (main): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (4): ResBlock(\n",
       "        (block1): Sequential(\n",
       "          (0): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "          (1): Swish()\n",
       "          (2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (temb_proj): Sequential(\n",
       "          (0): Swish()\n",
       "          (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "        (block2): Sequential(\n",
       "          (0): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (1): Swish()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (attn): Identity()\n",
       "      )\n",
       "      (5): ResBlock(\n",
       "        (block1): Sequential(\n",
       "          (0): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "          (1): Swish()\n",
       "          (2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (temb_proj): Sequential(\n",
       "          (0): Swish()\n",
       "          (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "        (block2): Sequential(\n",
       "          (0): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (1): Swish()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (attn): Identity()\n",
       "      )\n",
       "      (6): ResBlock(\n",
       "        (block1): Sequential(\n",
       "          (0): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "          (1): Swish()\n",
       "          (2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (temb_proj): Sequential(\n",
       "          (0): Swish()\n",
       "          (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "        (block2): Sequential(\n",
       "          (0): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (1): Swish()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (attn): Identity()\n",
       "      )\n",
       "      (7): UpSample(\n",
       "        (main): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (8): ResBlock(\n",
       "        (block1): Sequential(\n",
       "          (0): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "          (1): Swish()\n",
       "          (2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (temb_proj): Sequential(\n",
       "          (0): Swish()\n",
       "          (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "        (block2): Sequential(\n",
       "          (0): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (1): Swish()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (attn): AttnBlock(\n",
       "          (group_norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (proj_q): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (proj_k): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (proj_v): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (9): ResBlock(\n",
       "        (block1): Sequential(\n",
       "          (0): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "          (1): Swish()\n",
       "          (2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (temb_proj): Sequential(\n",
       "          (0): Swish()\n",
       "          (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "        (block2): Sequential(\n",
       "          (0): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (1): Swish()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (attn): AttnBlock(\n",
       "          (group_norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (proj_q): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (proj_k): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (proj_v): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (10): ResBlock(\n",
       "        (block1): Sequential(\n",
       "          (0): GroupNorm(32, 384, eps=1e-05, affine=True)\n",
       "          (1): Swish()\n",
       "          (2): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (temb_proj): Sequential(\n",
       "          (0): Swish()\n",
       "          (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "        (block2): Sequential(\n",
       "          (0): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (1): Swish()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (shortcut): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (attn): AttnBlock(\n",
       "          (group_norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (proj_q): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (proj_k): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (proj_v): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (11): UpSample(\n",
       "        (main): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (12): ResBlock(\n",
       "        (block1): Sequential(\n",
       "          (0): GroupNorm(32, 384, eps=1e-05, affine=True)\n",
       "          (1): Swish()\n",
       "          (2): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (temb_proj): Sequential(\n",
       "          (0): Swish()\n",
       "          (1): Linear(in_features=512, out_features=128, bias=True)\n",
       "        )\n",
       "        (block2): Sequential(\n",
       "          (0): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (1): Swish()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (shortcut): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (attn): Identity()\n",
       "      )\n",
       "      (13): ResBlock(\n",
       "        (block1): Sequential(\n",
       "          (0): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (1): Swish()\n",
       "          (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (temb_proj): Sequential(\n",
       "          (0): Swish()\n",
       "          (1): Linear(in_features=512, out_features=128, bias=True)\n",
       "        )\n",
       "        (block2): Sequential(\n",
       "          (0): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (1): Swish()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (shortcut): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (attn): Identity()\n",
       "      )\n",
       "      (14): ResBlock(\n",
       "        (block1): Sequential(\n",
       "          (0): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (1): Swish()\n",
       "          (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (temb_proj): Sequential(\n",
       "          (0): Swish()\n",
       "          (1): Linear(in_features=512, out_features=128, bias=True)\n",
       "        )\n",
       "        (block2): Sequential(\n",
       "          (0): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (1): Swish()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (shortcut): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (attn): Identity()\n",
       "      )\n",
       "    )\n",
       "    (tail): Sequential(\n",
       "      (0): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "      (1): Swish()\n",
       "      (2): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.load_state_dict(torch.load(config['model_path'])['model_state_dict'])\n",
    "sampler = DiffusionSampler(trainer.model).to(device)\n",
    "sampler.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_gather)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29761/1982931205.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mx_T\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mbatch_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_T\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#fake_data = sample(model, batch_size, (3, 32, 32), batch_size, device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/diffusion-models/model/ddpm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_T)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtimestamp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_T\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtimestamp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp_mean_variance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0meps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtimestamp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mx_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlog_var\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/diffusion-models/model/ddpm.py\u001b[0m in \u001b[0;36mp_mean_variance\u001b[0;34m(self, x_t, t)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;31m# posterior log_var\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mmodel_log_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposterior_var\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbetas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mmodel_log_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_log_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;31m# predict noise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/diffusion-models/model/ddpm.py\u001b[0m in \u001b[0;36mextract\u001b[0;34m(v, t, x_shape)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbroadcasting\u001b[0m \u001b[0mpurposes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \"\"\"\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_gather)"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    x_T = torch.randn((batch_size, 3, 32, 32))\n",
    "    batch_images = sampler(x_T).cpu()\n",
    "\n",
    "#fake_data = sample(model, batch_size, (3, 32, 32), batch_size, device)\n",
    "#torch.save(fake_data, 'fake_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 32, 32]) torch.float32\n",
      "torch.Size([64, 3, 32, 32]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "real_data = next(iter(dataloader))[0]\n",
    "real_data = denormalize(real_data).detach().cpu()\n",
    "\n",
    "fake_data = torch.load('fake_data.pt')\n",
    "fake_data = denormalize(fake_data).detach().cpu()\n",
    "\n",
    "print(real_data.shape, real_data.dtype)\n",
    "print(fake_data.shape, fake_data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8390376af0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(real_data[0,...].permute(1, 2, 0).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.923732280731201"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fid = fid_score(real_data, fake_data)\n",
    "fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fa2a54aadeef7a5edda050beeabc64402f8cd98f2e7f65b5261d04995015ea29"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
