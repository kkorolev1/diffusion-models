{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import os\n",
    "\n",
    "from model.datasets import get_loaders\n",
    "from model.ddpm import DiffusionTrainer, DiffusionSampler\n",
    "from model.unet import Unet\n",
    "from model.training import train, sample\n",
    "from model.utils import SaveBestModel, load_model, plot_images\n",
    "from model.metrics import fid_score\n",
    "\n",
    "import gc\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7087"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "CUDA = 0\n",
    "batch_size = 32\n",
    "\n",
    "train_loader, val_loader = get_loaders('cifar10', batch_size=batch_size)\n",
    "device = torch.device(f\"cuda:{CUDA}\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 177.72 MiB already allocated; 13.19 MiB free; 180.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m config \u001b[39m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m2e-4\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mstart_epoch\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmodel_path\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mbin/cifar10.pth\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      7\u001b[0m }\n\u001b[1;32m      9\u001b[0m unet \u001b[39m=\u001b[39m Unet(T\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m, ch\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m, ch_mult\u001b[39m=\u001b[39m[\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m], attn\u001b[39m=\u001b[39m[\u001b[39m1\u001b[39m], num_res_blocks\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, dropout\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m trainer \u001b[39m=\u001b[39m DiffusionTrainer(unet)\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m     12\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam(trainer\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mconfig[\u001b[39m'\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     13\u001b[0m \u001b[39m#optimizer = optim.SGD(model.parameters(), lr=args.lr)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m#scheduler = torch.optim.lr_scheduler.LambdaLR(optim, lr_lambda=lambda epoch: min(epoch, config['warmup']) / config['warmup'])\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/kkorolev/lib/python3.8/site-packages/torch/nn/modules/module.py:989\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    986\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m    987\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> 989\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[0;32m~/.conda/envs/kkorolev/lib/python3.8/site-packages/torch/nn/modules/module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    640\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 641\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    643\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    644\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    645\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    646\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    652\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/kkorolev/lib/python3.8/site-packages/torch/nn/modules/module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    640\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 641\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    643\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    644\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    645\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    646\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    652\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 641 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/kkorolev/lib/python3.8/site-packages/torch/nn/modules/module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    640\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 641\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    643\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    644\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    645\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    646\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    652\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/kkorolev/lib/python3.8/site-packages/torch/nn/modules/module.py:664\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    661\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    662\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    663\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 664\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    665\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    666\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/.conda/envs/kkorolev/lib/python3.8/site-packages/torch/nn/modules/module.py:987\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[1;32m    985\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    986\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> 987\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 177.72 MiB already allocated; 13.19 MiB free; 180.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'lr': 2e-4,\n",
    "    'start_epoch': 0,\n",
    "    'n_epochs': 5,\n",
    "    'warmup': 5000,\n",
    "    'model_path': 'bin/cifar10.pth'\n",
    "}\n",
    "\n",
    "unet = Unet(T=1000, ch=128, ch_mult=[1, 2, 2, 2], attn=[1], num_res_blocks=2, dropout=0.1)\n",
    "trainer = DiffusionTrainer(unet).to(device)\n",
    "\n",
    "optimizer = optim.Adam(trainer.parameters(), lr=config['lr'])\n",
    "#optimizer = optim.SGD(model.parameters(), lr=args.lr)\n",
    "#scheduler = torch.optim.lr_scheduler.LambdaLR(optim, lr_lambda=lambda epoch: min(epoch, config['warmup']) / config['warmup'])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "\n",
    "model_saver = SaveBestModel()\n",
    "\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1/5:   0%|          | 0/704 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Unable to find a valid cuDNN algorithm to run convolution",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train(\n\u001b[1;32m      2\u001b[0m     trainer,\n\u001b[1;32m      3\u001b[0m     optimizer,\n\u001b[1;32m      4\u001b[0m     scheduler,\n\u001b[1;32m      5\u001b[0m     train_loader,\n\u001b[1;32m      6\u001b[0m     val_loader,\n\u001b[1;32m      7\u001b[0m     device,\n\u001b[1;32m      8\u001b[0m     config[\u001b[39m'\u001b[39;49m\u001b[39mstart_epoch\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m+\u001b[39;49m config[\u001b[39m'\u001b[39;49m\u001b[39mn_epochs\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m      9\u001b[0m     config[\u001b[39m'\u001b[39;49m\u001b[39mstart_epoch\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     10\u001b[0m     model_saver,\n\u001b[1;32m     11\u001b[0m     config[\u001b[39m'\u001b[39;49m\u001b[39mmodel_path\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     12\u001b[0m     writer\n\u001b[1;32m     13\u001b[0m )\n",
      "File \u001b[0;32m~/diffusion-models/model/training.py:58\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, scheduler, train_loader, val_loader, device, n_epochs, start_epoch, model_saver, model_path, writer)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(model, optimizer, scheduler, train_loader, val_loader, device, n_epochs, start_epoch, model_saver, model_path, writer\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     57\u001b[0m     \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(start_epoch, n_epochs):\n\u001b[0;32m---> 58\u001b[0m         train_loss \u001b[39m=\u001b[39m train_epoch(model, optimizer, train_loader, device, \u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mTraining epoch \u001b[39;49m\u001b[39m{\u001b[39;49;00mepoch\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00mn_epochs\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     59\u001b[0m         val_loss \u001b[39m=\u001b[39m validate_epoch(model, val_loader, device, \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mValidating epoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mn_epochs\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     61\u001b[0m         \u001b[39mif\u001b[39;00m scheduler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/diffusion-models/model/training.py:32\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, optimizer, dataloader, device, tqdm_desc)\u001b[0m\n\u001b[1;32m     28\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     30\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 32\u001b[0m loss \u001b[39m=\u001b[39m model(img)\u001b[39m.\u001b[39mmean()\n\u001b[1;32m     33\u001b[0m epoch_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem() \u001b[39m*\u001b[39m img\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m     35\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.conda/envs/kkorolev/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/diffusion-models/model/ddpm.py:39\u001b[0m, in \u001b[0;36mDiffusionTrainer.forward\u001b[0;34m(self, x_0)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39m# using closed form to compute x_t using x_0 and noise\u001b[39;00m\n\u001b[1;32m     36\u001b[0m x_t \u001b[39m=\u001b[39m extract(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msqrt_alpha_prods, t, x_0\u001b[39m.\u001b[39mshape) \u001b[39m*\u001b[39m x_0 \u001b[39m+\u001b[39m \\\n\u001b[1;32m     37\u001b[0m       extract(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msqrt_one_minus_alpha_prods, t, x_0\u001b[39m.\u001b[39mshape) \u001b[39m*\u001b[39m eps\n\u001b[0;32m---> 39\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mmse_loss(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x_t, t), eps, reduction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/kkorolev/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/diffusion-models/model/unet.py:219\u001b[0m, in \u001b[0;36mUnet.forward\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m    217\u001b[0m temb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtime_embedding(t)\n\u001b[1;32m    218\u001b[0m \u001b[39m# Downsampling\u001b[39;00m\n\u001b[0;32m--> 219\u001b[0m h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhead(x)\n\u001b[1;32m    220\u001b[0m hs \u001b[39m=\u001b[39m [h]\n\u001b[1;32m    221\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdownblocks:\n",
      "File \u001b[0;32m~/.conda/envs/kkorolev/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/kkorolev/lib/python3.8/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/.conda/envs/kkorolev/lib/python3.8/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unable to find a valid cuDNN algorithm to run convolution"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    trainer,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    device,\n",
    "    config['start_epoch'] + config['n_epochs'],\n",
    "    config['start_epoch'],\n",
    "    model_saver,\n",
    "    config['model_path'],\n",
    "    writer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to sample 1 batches\n",
      "Sampling 1 batch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [04:03<00:00,  4.11it/s]\n"
     ]
    }
   ],
   "source": [
    "fake_data = sample(model, batch_size, (3, 32, 32), batch_size, device)\n",
    "torch.save(fake_data, 'fake_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 32, 32]) torch.float32\n",
      "torch.Size([64, 3, 32, 32]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "real_data = next(iter(dataloader))[0]\n",
    "real_data = denormalize(real_data).detach().cpu()\n",
    "\n",
    "fake_data = torch.load('fake_data.pt')\n",
    "fake_data = denormalize(fake_data).detach().cpu()\n",
    "\n",
    "print(real_data.shape, real_data.dtype)\n",
    "print(fake_data.shape, fake_data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8390376af0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(real_data[0,...].permute(1, 2, 0).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.923732280731201"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fid = fid_score(real_data, fake_data)\n",
    "fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kkorolev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f404e0e273a4f0796c7e39d3cee33e66306a58991d52ed6c42396fee84b35bae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
